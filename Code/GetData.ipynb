{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DownLoad Data\n",
    "Make sure' DownloadData.yaml' is in accessible location\n",
    "\n",
    "Running the code below will download the data onto your computer. The files are fairly large 27GB\n",
    "## LVIS = Large Vocabulary Instance Segmentation\n",
    "Created to address the “long tail” problem in object recognition → meaning:\n",
    "→ some objects/classes appear frequently, but many appear rarely.\n",
    "1,203 object categories → more than COCO (which has only 80)\n",
    "Provides instance segmentation masks (detailed pixel-level outlines of objects)\n",
    "Built on top of COCO images but adds much finer-grained and more diverse object labels\n",
    "Open-vocabulary → supports detection of rare or unusual objects (great for generalization)\n",
    "\n",
    "## in the future i plan on murging this dataset with the ADE20K (MIT Scene Parsing) , Open Images Dataset (OID) for backgrounds and increased diversity respectivly after we develop a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # load a dummy model\n",
    "model.val(data='downloaddata.yaml', save=False, batch=1, imgsz=640)#download Test/Train/Val dataset"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
